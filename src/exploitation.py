from qlearning_de import differential_evolution_qlearning
from config import *

print("\n" + "=" * 60)

for fname in SELECTED_FUNCTIONS:
    sys.stdout = Logger(f"logs/exploitation___{fname}.txt")
    print(f"USING trained Q-table | Function: {fname}")
    func = getattr(functions, fname)
    optimum = OPTIMUM_VALUES.get(fname, None)
    results = []

    # Load the trained Q-table from file
    q_file = f"q_tables/q_table_{fname}.npy"
    try:
        Q_loaded = np.load(q_file)
        print(f"Loaded Q-table from file: {q_file}")
    except FileNotFoundError:
        print(f"File {q_file} not found. Using an empty Q-table.")
        Q_loaded = np.zeros_like(Q_global)

    # Reset visited states and counters
    visited_states.clear()
    state_visit_counts.fill(0)

    for run in range(EXPLOITATION_RUNS):
        print(f"\n--- Exploitation {run + 1}/{EXPLOITATION_RUNS} ---")

        # Initialize Q_global with the loaded Q before each run
        Q_global[:] = Q_loaded

        result = differential_evolution_qlearning(func, fname, Q_global, config=EXPLOITATION_CONFIG, optimum=optimum)
        results.append(result)

